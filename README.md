# vanilla-transformer-implementations

### Objectives
- understand the building blocks of vanilla transformer
- try out all the pytorch moudles used in the implementations

### References
- [Attention Is All You Need](https://paperswithcode.com/paper/attention-is-all-you-need)
- [The Annotated Transformer](http://nlp.seas.harvard.edu/annotated-transformer/)
- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
- [Pytorch Transformers from Scratch (Attention is all you need)](https://www.youtube.com/watch?v=U0s0f995w14)
- [Transformer: Concepts, Building Block, Attention, Sample Implementation in PyTorch](https://www.youtube.com/watch?v=6PmIoCnqcFU)
- [[딥러닝 기계 번역] Transformer: Attention Is All You Need (꼼꼼한 딥러닝 논문 리뷰와 코드 실습)
](https://www.youtube.com/watch?v=AA621UofTUA)
- [nlp-tutorial](https://github.com/graykode/nlp-tutorial)
- [labml.ai Deep Learning Paper Implementations](https://github.com/labmlai/annotated_deep_learning_paper_implementations)
